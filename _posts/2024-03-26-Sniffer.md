---
layout: post
title: "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection"
published: true
image: 
  path: /images/Sniffer/logo.png
---

<div class="img-div-any-width" markdown="0">
  <image src="/images/Sniffer/introcase.jpg"/>
</div>


<strong>Peng Qi, Zehong Yan, Wynne Hsu, Mong Li Lee</strong>

<blockquote class='subtle'>
  CVPR, 2024 / <a href="https://arxiv.org/pdf/2403.03170">PDF</a> / <a href="https://pengqi.site/Sniffer/">Project Page</a> / <a href="https://github.com/MischaQI/Sniffer">Code</a> / <a href="https://youtu.be/zPTZnz9nhlI">Video</a>
</blockquote>


Focusing on the innovative research perspective of explainable out-of-context misinformation detection, this paper proposes a new multimodal large language model, SNIFFER, designed to offer both accurate detection and persuasive explanations simultaneously. Enhanced by two-stage instruction tuning and retrieval-enhancement techniques, SNIFFER effectively models both internal image-text inconsistency and external claim-evidence relationships.
<!--more-->

<div align="center">
  [![Python Versions](https://img.shields.io/badge/-Python_3.7_%7C_3.8_%7C_3.9_%7C_3.10-blue?logo=python&logoColor=white)](https://www.python.org/downloads/)
</div>

<div class="publication-links">
              
  <!-- <span class="link-block">
    <a href="https://arxiv.org/pdf/2311.14603"
        class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="fas fa-file-pdf"></i>
      </span>
      <span>Paper</span>
    </a>
  </span> -->
  <span class="link-block">
    <a href="https://arxiv.org/abs/2403.03170" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="ai ai-arxiv"></i>
      </span>
      <span>arXiv</span>
    </a>
  </span>
  <!-- Video Link. -->
  <span class="link-block">
    <a href="https://youtu.be/zPTZnz9nhlI" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <svg class="svg-inline--fa fa-youtube fa-w-18" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="youtube" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg><!-- <i class="fab fa-youtube"></i> Font Awesome fontawesome.com -->
      </span>
      <span>Video</span>
    </a>
  </span>
  <span class="link-block">
    <a href="https://huggingface.co/MischaQI/SNIFFER" target="_blank" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <!-- <i class="fas fa-share-square"></i> -->
        <svg class="svg-inline--fa fa-link fa-w-16" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="link" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg><!-- <i class="fa fa-link"></i> Font Awesome fontawesome.com -->
      </span>
      <span>Model</span>
    </a>
  </span>
  <!-- <span class="link-block">
    <a href="https://github.com/MischaQI/Sniffer" target="_blank"
      class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fas fa-share-square"></i> -->
        <!-- <i class="fab fa-github"></i>
      </span>
      <span>Code</span>
    </a>
  </span> -->
  <!-- Code Link. -->
  <!-- <span class="link-block">
    <a href="https://github.com/HeliosZhao/Animate124"
        class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          <i class="fab fa-github"></i>
      </span>
      <span>Code</span>
      </a>
  </span> -->
  <!-- <span class="link-block">
    <a href="https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K" target="_blank"
      class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fas fa-database"></i>
      </span>
      <span>Dataset</span>
    </a>
  </span> -->

</div>

## Abstract
Misinformation is a prevalent societal issue due to its potential high risks. Out-Of-Context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which is essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on InstructBLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities and the second stage leverages language-only GPT-4 generated OOC-specific instruction data to fine-tune the model's discriminatory powers. Enhanced by external tools and retrieval, SNIFFER not only detects inconsistencies between text and image but also utilizes external knowledge for contextual verification. Our experiments show that SNIFFER surpasses the original MLLM by over 40% and outperforms state-of-the-art methods in detection accuracy. SNIFFER also provides accurate and persuasive explanations as validated by quantitative and human evaluations.


## Framework
<div class="img-div-any-width" markdown="0">
  <image src="/images/Sniffer/framework.jpg"/>
</div>

Architecture of the proposed framework SNIFFER. For a given image-text pair, SNIFFER conducts a two-pronged analysis: (1) it checks the consistency of the image and text content (internal checking), and (2) it examines the relevance between the context of the retrieved image and the provided text (external checking). The outcomes of both these verification processes are then considered by S NIFFER to arrive at a final judgment and explanation.

## Multimodal Instrucion-Following Data

### Instruction Tuning Process

<div class="img-div-any-width" markdown="0">
  <image src="/images/Sniffer/process.jpg"/>
</div>

### Task-Specific Instruction Construction (with judgment and explanation)

<center>
  <image src="/images/Sniffer/oocdata.jpg"/>
</center>

## Performance
<p align="center">
  <image src="/images/Sniffer/detection.jpg"/>
</p>

## BibTeX
If you found this work helpful for your research, please cite it as following:
```
@inproceedings{qi2023sniffer,
  author      = {Qi, Peng and Yan, Zehong and Hsu, Wynne and Lee, Mong Li},
  title       = {SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection},
  booktitle   = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year        = {2024}
}
```


<footer class="footer">
  <p>
    This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a hred="https://pengqi.site/Sniffer/">Sniffer</a>. Thanks for the great work.
  </p>
</footer>
