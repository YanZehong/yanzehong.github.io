---
layout: post
title: "Modeling Complex Interactions in Long Documents for Aspect-Based Sentiment Analysis"
published: true
---

<p align="center">
  <strong>Zehong Yan, Wynne Hsu, Mong Li Lee, David Roy Bartram-Shaw</strong>
</p>

<p align="center">
  <a href="https://workshop-wassa.github.io/"> 
    <img src="https://img.shields.io/badge/arXiv-B31B1B?logo=arxiv&labelColor=grey" />
  </a> 
  <a href="https://github.com/YanZehong/dart"> 
    <img src="https://img.shields.io/badge/Model-181717?logo=github&labelColor=grey" />
  </a> 
  <a href="https://github.com/YanZehong/SocialNews"> 
    <img src="https://img.shields.io/badge/Data-4285F4?logo=googledocs&logoColor=white&labelColor=grey" />
  </a> 
</p>

<div class="img-div-any-width" markdown="0">
  <image src="/images/dart/intro.jpeg" width="310" height="350" />
</div>


<blockquote class='subtle'>
  WASSA, ACL Workshop, 2024 / <a href="https://workshop-wassa.github.io/">PDF</a> / <a href="https://yanzehong.github.io/dart/">Project Page</a> / <a href="https://github.com/YanZehong/dart">Code</a> / <a href="https://github.com/YanZehong/SocialNews">Data</a>
</blockquote>


This work introduces a hierarchical Transformer-based architecture, DART, that encodes information at different level of granularities with attention aggregation mechanisms to learn the local and global aspect-specific document representations. For empirical validation, we curate two datasets of long documents: one on social issues, and another covering various topics involving trust-related issues.
<!--more-->




## Abstract
<p align="justify">
  The growing number of online articles and reviews necessitates innovative techniques for document-level aspect-based sentiment analysis. Capturing the context in which an aspect is mentioned is crucial. Existing models have focused on relatively short reviews and may fail to consider distant contextual information. This is especially so in longer documents where an aspect may be referred to in multiple ways across dispersed sentences. This work introduces a hierarchical Transformer-based architecture that encodes information at different level of granularities with attention aggregation mechanisms to learn the local and global aspect-specific document representations. For empirical validation, we curate two datasets of long documents: one on social issues, and another covering various topics involving trust-related issues. Experimental results show that the proposed architecture outperforms state-of-the-art methods for document-level aspect-based sentiment classification. We also demonstrate the potential applicability of our approach for long document trust prediction.
</p>


## Framework
<div class="img-div-any-width" markdown="0">
  <image src="/images/dart/framework.jpeg"/>
</div>

The proposed DART framework consists of four key blocks: 

- **Sentence Encoding Block.** This block focuses on transforming the document into individual sentences and using a pretrained language model to generate representations for every sentence-aspect combination.

- **Global Context Interaction Block.** This block employs dual transformer encoders to model interactions among sentences and generate context-aware sentence embeddings. This is a crucial component of DART as it captures essential aspect-specific information across long-range dependencies.


- **Aspect Aggregation Block.** This block aggregates the 
contextually enriched  sentence embedding to produce an aspect-specific representation of the entire document. 

- **Sentiment Classification Block.** With the document representation obtained, this block leverages a two-layered Multilayer Perceptron (MLP) to predict the sentiment for  the aspect.


## Performance in SocialNews
<div class="img-div-any-width" markdown="0">
  <image src="/images/dart/result-1.png"/>
</div>

<div class="img-div-any-width" markdown="0">
  <image src="/images/dart/result.jpeg"/>
</div>



## BibTeX
If you found this work helpful for your research, please cite it as following:
```
@inproceedings{yan2024modeling,
  author      = {Yan, Zehong and Hsu, Wynne and Lee, Mong Li and Bartram-Shaw, David Roy},
  title       = {Modeling Complex Interactions in Long Documents for Aspect-Based Sentiment Analysis},
  booktitle   = {Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis},
  year        = {2024}
}
```


<footer class="footer">
  <p>
    This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a hred="https://pengqi.site/Sniffer/">Sniffer</a>. Thanks for the great work.
  </p>
</footer>
